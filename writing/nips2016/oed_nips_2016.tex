\documentclass{article}

% to do (5/16)

%% put more sparkles around writing OED in a program. Why is this clever and useful?

%% introduce max Entropy prior early (could also be interpolation between max ent and the predictive)
%%%% results of sequence prediction (formerly, "randomness") w.r.t. maxEnt vs. predictive (discuss why we think maxEnt is giving a better prediction here)

%% Figure 3 histogram: vertical line with AIG
%% create n_subjects analysis figure (a la FIgure 3, line plot) for sequence prediction... bootstrap up to n=100 to observe crossover


% if you need to pass options to natbib, use, e.g.:
% \PassOptionsToPackage{numbers, compress}{natbib}
% before loading nips_2016
%
% to avoid loading the natbib package, add option nonatbib:
\usepackage[nonatbib]{nips_2016}

%\usepackage{nips_2016}

% to compile a camera-ready version, add the [final] option, e.g.:
% \usepackage[final]{nips_2016}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
%\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{fancyvrb}
\usepackage{multirow}
\usepackage{color}


% HT http://tex.stackexchange.com/a/151987/41154
\DeclarePairedDelimiterX{\infdivx}[2]{(}{)}{%
  #1\;\delimsize\|\;#2%
}
\newcommand{\dkl}{D_\mathrm{KL}\infdivx}

\usepackage{listings}
\definecolor{lightgray}{rgb}{.9,.9,.9}
\definecolor{darkgray}{rgb}{.4,.4,.4}
\definecolor{purple}{rgb}{0.65, 0.12, 0.82}
\definecolor{orange}{rgb}{1,0.5,0}

\definecolor{Red}{RGB}{255,0,0}
\newcommand{\red}[1]{\textcolor{Red}{#1}}
\definecolor{Green}{RGB}{10,200,100}
\definecolor{Blue}{RGB}{10,100,200}
\newcommand{\ndg}[1]{\textcolor{Green}{[ndg: #1]}}
\newcommand{\mht}[1]{\textcolor{Blue}{[mht: #1]}}
\newcommand{\lou}[1]{\textcolor{orange}{[lou: #1]}}

% casual outlining font
\newcommand{\cas}[1]{ \textsf{\color{darkgray} \scriptsize #1} }

\lstdefinelanguage{JavaScript}{
  keywords={typeof, new, true, false, catch, function, return, null, catch, switch, var, if, in, while, do, else, case, break},
  keywordstyle=\color{blue}\bfseries,
  ndkeywords={class, export, boolean, throw, implements, import, this},
  ndkeywordstyle=\color{darkgray}\bfseries,
  identifierstyle=\color{black},
  sensitive=false,
  comment=[l]{//},
  morecomment=[s]{/*}{*/},
  commentstyle=\color{purple}\ttfamily,
  stringstyle=\color{red}\ttfamily,
  morestring=[b]',
  morestring=[b]"
}

\lstset{
   language=JavaScript,
   backgroundcolor=\color{white},
   extendedchars=true,
   basicstyle=\footnotesize\ttfamily,
   showstringspaces=false,
   showspaces=false,
   numbers=none,
   numberstyle=\footnotesize,
   numbersep=9pt,
   tabsize=2,
   breaklines=true,
   showtabs=false,
   captionpos=b
}



\usepackage[ruled,vlined]{algorithm2e}

\newcommand{\ud}{\,\mathrm{d}}
\DeclareMathOperator*{\argmax}{arg\,max}


\title{Practical optimal experiment design with probabilistic programs}

% The \author macro works with any number of authors. There are two
% commands used to separate the names and addresses of multiple
% authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to
% break the lines. Using \AND forces a line break at that point. So,
% if LaTeX puts 3 of 4 authors names on the first line, and the last
% on the second line, try using \AND instead of \And before the third
% author name.

\author{
  David S.~Hippocampus\thanks{Use footnote for providing further
    information about author (webpage, alternative
    address)---\emph{not} for acknowledging funding agencies.} \\
  Department of Computer Science\\
  Cranberry-Lemon University\\
  Pittsburgh, PA 15213 \\
  \texttt{hippo@cs.cranberry-lemon.edu} \\
  %% examples of more authors
  %% \And
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
  %% \AND
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
  %% \And
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
  %% \And
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
}

\begin{document}
% \nipsfinalcopy is no longer used

\maketitle

\begin{abstract}

Designing good scientific experiments requires ingenuity, rigor, and patience to consider a large space of possible experiments.
With the growing popularity of formal models, part of this time-consuming process can be automated.
Here, we present a general and principled approach to experiment design.
Our system is based on a user-friendly probabilistic programming language (PPL).
Using such a high-level and universal modeling language means details of experiment selection calculation can be hidden from the scientist, without loss of generality; she needs only represent her hypothesis and space of potential experiments.
We apply this system to differentiating competing models of psychological phenomena, but the framework is general to any domain where probabilistic models are used to represent theories.
%We consider a number of problems specific to psychological phenomena: dealing with noisy responses and deciding on the number of subjects.
We validate our framework using case studies in the psychology of randomness and categorization.
We find strong empirical validation that our automatically designed optimal experiments were indeed optimal.
Our framework opens up a number of interesting questions, which we explore in the discussion.


\end{abstract}

%\mht{I think in practice ``the space of possible experiments'' is the same thing as an ``empirical paradigm''. This terminology may be useful in our exposition.}

\section{Introduction}
%\lou{start off more generally, don't specialize too much for psychology.}
%\ndg{agree: first talk about OED in general, and why we should do OED within a PPL setup, then talk about psych as a target domain.}
Designing scientific experiments is hard.
Scientists must have hypotheses and reason over a potentially large space of possible experiments.
Formal models alleviate some of these issues.
Models make explicit hypotheses about observed data, and thus make it easier (or in some cases, possible) to explore the implications of a set of theoretical ideas.
However, exploring models can be time-consuming and searching through a large space of possible experiments is still largely driven by the scientist's intuition.
This intuition may be biased towards experiments that show qualitative differences between models, even when they are not very informative.
%\ndg{point out that this intuition can be wrong -- foreshadow MS result...}
This need not be the case: If both the set of hypotheses and the space of experiments are explicit, then we can partially \emph{automate} experiment design as a sort of active learning problem, searching for experiments that maximally update our beliefs about a scientific question.

We present a general and principled framework for experiment design that uses a Bayesian approach to find experiments that best distinguish competing hypotheses.
For such a framework to be domain-general, the computation for experiment selection must be automatic.
This is only possible with a common formalism for specifying hypotheses and experiments.
\emph{Probabilistic programming languages} (PPLs) are such a formalism; they are high-level and universal languages for expressing probabilistic models.
This is a crucial step in making a practical OED system: Once you're using a PPL to formalize your hypotheses, OED comes for free.

We first describe our framework in general terms and then apply it in two case studies from cognitive psychology, a field of where experiments have certain challenging features: human participants give noisy responses, experimental results are sensitive to sample size, and computational models often do not make direct predictions about experimental data, instead requiring \emph{linking functions}.
In the first case study, we consider the problem of disambiguating three toy models of perceptions of subjective randomness.
In the second case study, we go beyond toy models and consider a classic paper on human categorization learning that compared two models using an experiment designed by hand; we find that OED discovers experiments that are more effective in an information-theoretic sense.
Our general system opens a number of rich areas for future development, which we explore in the discussion.

%We conclude by highlighting the generality of the approach and areas of future work.
%\ndg{all the parts are here. needs smoothing. make it clearer that using PPL to represent hypotheses is a key step in making the system practical.}

%    \begin{itemize}
%        \item It is difficult to discriminate models of psychological processes
%        \item Experiments are expensive
%        \item We present a general, turn-key approach to design experiments that best disambiguate competing models using a Bayesian framework
%        \item This technique is not directly related to Bayesian models of cognition. It can be used on any (formal / probabilistic) model, including Bayesian models of cognition
%        \item Despite the previous attempts in this field, there are a number of pragmatic issues that make it difficult to readily apply OED techniques for psychology, including:
%        \begin{itemize}
%            \item A variety of proposed optimization criteria, which puts the burden on researchers to have sufficient expertise to select the appropriate approach
%            \item A lack of an established pipeline, requiring researchers to develop a language to formalize psychological models and write an OED optimization engine
%            \item A lack of analysis in dealing with practical experimental concerns such as:
%                \begin{itemize}
%                    \item Noisy responses from participants
%                    \item The ideal number of participants for a study
%                    \item The ambiguity of linking functions of dependent measures
%                \end{itemize}
%        \end{itemize}
%    \end{itemize}


\section{Experiment design framework}
\label{s:bayes}

\ndg{this section needs to be smoothed out. (should still be short...) first talk about models (M), experiments (X), and results (Y). Then talk about posterior on models and information gain. Then talk about expected results (first assuming models are true, then relaxing to uninformative). Finally the argmax objective.}

Let $P(M)$ be a prior distribution on models or hypotheses, $P(X)$ a prior on experiments, and $P(Y)$ a prior on possible responses.
A model $m$ is a conditional distribution $P_m(Y \mid X)$ that expresses predictions about responses $y_i$ for different possible experiments $x_i$ (we will use the notation $m(x)$ as shorthand for $P_m(Y \mid X = x)$).
Thus, experiments and responses can update the distribution on models into a posterior distribution on models.
The amount of information gain can be given by the KL divergence between this distribution and the prior $ \dkl{ P(M \mid X = x, Y = y) }{ P(M) } $.

To compute the expected information gain, we must express our beliefs about the expected results $p(y ; x)$.
If we believe $M$ contains the true model, the predictive distribution of responses implied by the models is appropriate:
$$ p(y ; x) = \sum\limits_{m}p_m(y \mid x)p(m) $$
where $p_m(y \mid x)$ is the distribution on responses $y$ for experiment $x$ predicted by model $m$.
In other cases, we would not suppose the true model is contained in $M$; here, a maximum entropy or uninformative distribution is a natural choice for $p(y ; x)$.

The goal of OED is to find the experiment $x^{*}$ that maximizes the expected information gain about the belief distribution on models $P(M \mid X = x^{*})$.
The optimal experiment $x^*$ maximizes the expected KL divergence over the space of responses:
\begin{align}
x^{*} &= \argmax_{x} \sum\limits_{y} p(y ; x) \dkl{ P(M \mid X = x, Y = y) }{ P(M) } \label{eq:oed}
\end{align}

\lou{discuss linking functions.. in coins example we assume that subjects are iid and that each subject's response is conditionally iid given their latent values but we could relax these assumptions}

\lou{give example}

\subsection{Probabilistic program hypothesis specification}

%\ndg{cut this paragraph, or move to intro.}
%Complex probabilistic models require new representations to support their specification. Probabilistic programs are such a representation, extending probabilistic graphical models with insights from programming language research.
%PPLs provide compositionality and abstraction, which are incredibly useful for articulating clear, formal hypotheses. In addition, PPLs separate model description from implementation, and generic tools for calculating efficient probabilistic inference can be swapped in on a need-to-use basis, depending on the details of the probabilistic model.
%We implement our OED system as a probabilistic program, allowing us to harness these features.

We use the probabilistic programming language WebPPL (\url{webppl.org}), a small but feature-rich probabilistic programming language embedded in Javascript, to implement OED \cite{dippl}.
WebPPL uses primitive Distribution objects (e.g. \lstinline{Binomial}), which can be accessed with a number of different methods: \lstinline{sample}, \lstinline{score}, \lstinline{support}.
For instance, \lstinline|sample(Binomial({n: 4, p: 0.5}))| returns a sample from the Binomial distribution with parameters $n=4, p = 0.5$. \lstinline|score(Binomial({n: 4, p: 0.5}), 2)| will return the log-probability of the value 2 under this Binomial distribution.
Oftentimes, we are interested in posterior inference. Let's say we are interested in the Binomial(4, 0.5) distribution conditional on at least 2 positive outcomes. In WebPPL, we would write this as:
%
\begin{lstlisting}[mathescape, label={code:webppl}, caption = {Posterior inference in WebPPL.}]
var myBinomialModel = function(){
	var x = sample(Binomial({n: 4, p: 0.5}))
	condition(x >= 2)
	return x
}
\end{lstlisting}
%
In Listing \ref{code:webppl}, we've constructed a function with no arguments (i.e., a thunk: \lstinline{myBinomialModel}), which samples from a Binomial distribution, uses the WebPPL primitive \lstinline{condition} to specify how we want to update our distribution, and returns the resulting sampled value \lstinline{x}.
\lstinline{condition} looks to see if the condition is satsfied (if $x\geq2$); if it is not, it re-weights the likelihood of that \emph{program execution} (composed of all of the random choices made before the condition statement) to 0.
\lstinline{condition} is a special case of \lstinline{factor}, which adjusts the (log) likelihood of the program execution by some value (most often, the log probability of the data under that program execution).

Notice how this model has not specified \emph{how} we are to construct a posterior distribution.
This is a convenient separation for the scientist interested in specifying formal hypotheses.
To do posterior inference, we would call this function with a generic inference routine \lstinline{Infer(myBinomialModel, method)}.
In \lstinline{method}, we would specify what inference algorithm we want to use.
WebPPL currently has several inference algorithms to choose from: MCMC, full Enumeration, Hamiltonian Monte Carlo, Sequential Monte Carlo, and Variational Inference.

%\ndg{make clear the two different uses of webppl here: to represent the scientific hypotheses (user-facing), and to implement the OED calculations (developer-facing). maybe separate subsection for the latter?}

\subsection{Probabilistic program OED implementation}

In addition to being used by the scientist to specify hypotheses, WebPPL can be used by developers to implement useful calculations.
Because we have expressed the space of models, experiments, and responses in the language of probability, it is straightforward to express Equation \ref{eq:oed} as a probabilistic program (see Listing \ref{code:oed-pp}).
This makes it clear that OED is an inference problem.
Attacking this problem using probabilistic programming allows us to separate the task of describing the problem (i.e., writing the generative model of OED) from the task of solving it (i.e., choosing/writing the inference algorithm).
In addition, framing OED this way gives us access to algorithms that are more sophisticated than previous research has considered  (e.g., HMC for continuous experiment spaces).
If we are not interested in the full distribution of information gain, we could substitute in an optimization operator \lstinline{Search()} rather than the posterior inference operator \lstinline{Infer()}.
%\lou{note that outermost Infer() could also be a Search()}

%\begin{minipage}{\linewidth}
\begin{lstlisting}[mathescape, label={code:oed-pp}, caption = {OED implementation. For clarity, we have omitted some book-keeping details.}]
var OED = function(mSample, xSample, ySample) {
  var mPrior = Infer(function() { mSample() })
  Infer(function() {
    var x = xSample()                    // ${\color{purple} p(x)}$
    var yPredictive = Infer(function() { // ${\color{purple} P(Y = y ; x)}$ (predictive)
      var y = ySample(), m = sample(mPrior)
      factor(score(m(x), y))
      return y
    })
    var KLDist = Infer(function() {  // ${\color{purple} \sum_{y} p(y) \dkl{ P(M \mid Y = y) }{ P(M) } }$
      var y = sample(yPredictive)
      var mPosterior = Infer(function() {
        var m = sample(mPrior)
        factor(score(m(x), y))
        return m.name
      })
      return KL(mPosterior, mPrior)
    })
    var EIG = expectation(KLDist)
    factor(EIG)
    return {x: x, EIG: EIG}
  })
}
\end{lstlisting}
%\end{minipage}
Our OED code is available as a WebPPL package---see \url{https://github.com/mhtess/webppl-oed}.
We next illustrate our system by applying it to distinguish psychological theories of randomness perception.

\section{Case study 1: Subjective randomness}
\label{s:tutorial}

\ndg{possibly we should cast this section as theories of sequence prediction, and connect to randomness perception as part of broader context?}

Human judgments about randomness are surprisingly systematic and nonuniform across equally likely outcomes -- for example, a sequence of outcomes of coin flips \lstinline{HTHTTTHH} is considered to be more random than the sequence \lstinline{HHHHHHHH} ~\cite{goodfellow38:jep, griffiths01:cogsci}.
%This discrepancy between human intuitions and statistical fact about randomness has garnered significant attention from both the mathematical~\cite{chaitin01:er, kac83:as, li97:kca} and psychological~\cite{falk81:pme, lopes82:jep, griffiths01:cogsci} literature.
\ndg{need to say that theories of randomness are formulated as posterior sleection, and we look at the simpler component theory of sequence prediction??}
There are many hypotheses one might have about what underlies human intuitions about randomness and prediction of the next observation in a sequence.
Here, we consider three simple hypotheses about the beliefs that participants have about the coin flips\footnote{These are computational-level models of a \emph{person's model} of the situation. For more details on this kind of cognitive modeling, see \url{https://probmods.org}}: (a) \emph{Fair coin}: participants assume the coin is fair, (b) \emph{Weighted coin}: participants believe the coin has some unknown bias (i.e., the probability of a \lstinline{H} outcome), (c) \emph{Markov coin}: participants believe the coin has some probability of transitioning between spans of \lstinline{H} and \lstinline{T} outcomes.
We consider an experimental setup where participants observe four flips of the same coin and are asked to predict the outcome of the next flip.


\subsection{Model space}

Formally, the set of models is $\{m_{\text{fair}}, m_{\text{weighted}}, m_{\text{markov}}\}$, the set of experimental designs $\mathcal{X}$ is the set of all possible sequences of four coin flips, and the set of responses $\mathcal{Y}$ is a choice between heads or tails for the fifth flip.

In $m_{\text{fair}}$, we model participants as believing that the coin has an equal probability of coming up heads or tails:

\begin{lstlisting}[caption=Fair coin model,  label={lst:m_fair}]
  var fairCoin = function(sequence) {
    Infer(function(){
      return flip(0.5)
    }, {method: 'Enumerate'})
  }
\end{lstlisting}

Note the type signature of this model -- it takes as input an experiment and returns a distribution on possible responses for the measurement of that experiment (here, judgments about the next coin flip).
This distribution is computed using a particular inference strategy, here, an exhaustive \lstinline{Enumerate} algorithm.
$m_{\text{bias}}$ generalizes this fair coin model---people assume the coin has some unknown bias, learn it from observations, and use it to predict the next coin flip:

\begin{lstlisting}[caption=Biased coin model,  label={lst:m_weighted}]
var coinWeights = [0.01,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.99]
var weightedCoin = function(seq) {
  Infer(function(){
    var bias = uniformDraw(coinWeights);
    var flipCoin = function(){ return flip(bias) };
    var sampledSequence = repeat(seq.length, flipCoin);
    condition(arrayEquals(seq,sampledSequence));
    return flipCoin()
  }, {method: 'Enumerate'})
}
\end{lstlisting}

$m_{\text{bias}}$ first samples a coin weight \lstinline{bias} from a discretized uniform distribution, and
then creates a helper function \lstinline{flipCoin} which samples observation from the weighted coin.
The model then generates a sequence of coin flips of the length of the sequence observed \lstinline{repeat(seq.length, flipCoin)} and conditions on this matching the observed sequence \lstinline{seq}.
The built-in function \lstinline{condition} rejects executions of the program that fail to match the condition \lstinline{arrayEquals(seq,sampledSequence)}.
The model returns the outcome of the next coin flip.

Finally, $m_{\text{markov}}$ assumes that the coin is generated by a Markov process where each coin flip depends on the previous coin flip.
The probability of transitioning from the current coin flip is inferred from the experiment prompt sequence, and is  then used to predict the next flip:

\begin{lstlisting}[caption=Markov coin model]
var markovCoin = function(seq) {
  Infer(function(){
    var switchProb =  uniformDraw(coin_weights);
    var sampleOne = function(lastFlip) { flip(switchProb) ? !lastFlip : lastFlip }
 	  var sampleSequence = function(flipsSoFar, n) {
      var nextFlip = sampleOne(last(flipsSoFar))
      return (n == 0) ? flipsSoFar
                      : sampleSequence(append(flipsSoFar, nextFlip),
                      		n - 1) };
	  var sampledSequence = sampleSequence([flip(0.5)], seq.length - 1)
    condition(arrayEquals(seq, sampledSequence));
    return sampleOne(last(sampledSequence))
  }, {method: 'Enumerate'})
}
\end{lstlisting}

\subsection{Predictions of optimal experiment design}

We run OED by calling the \lstinline{OED} function on a distribution of models and a distribution of experiments; it then returns the expected information gain for every experiment (Fig.~\ref{fig:run-coin}).
We first explore the expected information gain of experiments designed to disambiguate the fair coin model from the weighted coin model (Figure \ref{fig:run-coin}, left).
We see that the most informative experimenters here are \lstinline{HHHH} and \lstinline{TTTT}.
This makes intuitive sense --- the weighted model would infer a strongly biased coin and make a strong prediction, while the fair coin model is unaffected by the observed sequence.
\lou{note cases of 0 eig}

\begin{figure}[h]
\underline{\textsf{Input:}}
\begin{lstlisting}
OED({mSample: function() { uniformDraw([fairCoin, weightedCoin]) }),
     xSample: function() { repeat(4, flip) }, // experiment space
     ySample: function() { flip() }) // response space
\end{lstlisting}

\underline{\textsf{Output:}}\\
\includegraphics[width=\columnwidth]{img/coin_eig.pdf}
\caption{Running OED in the subjective randomness domain \mht{this is with the number of subjects that we collected; might want to make this for n = 1 (or n = 20) to highlight the symmetries}} \mht{Note this is also with the ignorance prior}
%\lou{make this figure in ggplot, clean it up}
\label{fig:run-coin}
\end{figure}

We also explore the experiments designed to disambiguate the weighted coin model from the Markov coin model (Figure \ref{fig:run-coin}, middle).
We see that \lstinline{HTHT} and \lstinline{THTH} are the most informative experiments, here.
This is also fairly intuitive -- the weighted model infers a 0.5 probability of heads and so assigns equal probability of heads and tails to the next flip, whereas the Markov infers that the probability of transitioning from one outcome to the other is quite high and assigns high probability to the opposite of the last observed value (\lstinline{T} for \lstinline{THTH} and \lstinline{H} for \lstinline{HTHT}).
We also see that \lstinline{HHHH} and \lstinline{TTTT} are now the least informative experiments.
Informally, this is because the models make the same predictions for these experiments, albeit for different reasons.
For instance, for \lstinline{HHHH}, the weighted model infers a high probability of heads and so assigns high probability of heads to the next flip.
The Markov model infers a low probability of transitioning from heads to tails, so it also assigns a high probability of heads to the next flip.

%Finally, the expected information gain of experiments designed to disambiguate all three models is more complex to understand.
%The information gain now depends on how well the experiments disambiguate all three models. Here, we see that for


\subsection{Empirical validation}
We validated our OED system by running all of 16 experiments and comparing expected information gain with the empirically measured information gain.
We recruited 320 participants from Amazon's Mechanical Turk.
We randomly assigned each participant to a single experiment (i.e., all of the 16 possible experiments were completed by $>=$20 unique participants).
Participants pressed a key to sequentially reveal the sequence of 4 flips and then made a prediction about the of the next coin flip (either heads or tails).
The experiment took about 30 seconds and participants were compensated \$0.10 for their involvement.
%The experiment in full can be viewed at \url{http://stanford.edu/~mtessler/oed/oed/experiments/subjective-randomness/experiment.html}

For each experiment $x_i$ and result $y_i$, we computed the expected information gain from running 20 participants\footnote{because we do client-side randomization, N's are not actually 20; we use the empirical N's for EIG} and compared this to the actual information gain,
$$\mathrm{AIG} = \dkl{P(M \mid Y = y_i, X = x_i)}{P(M)}$$
for different model comparison scenarios.
Figure \ref{fig:aig_vs_eig} shows that expected information gain is a reliable predictor of the empirical value of an experiment (minimum $r$ = 0.857).

\begin{figure}[h!]
\centering
\includegraphics[width=0.7\columnwidth]{img/coin_eig_aig_scatter_noText.pdf}
\caption{Actual information gain vs. Expected information gain for three model comparison setups. \lou{add trendlines, R values}}
\label{fig:aig_vs_eig}
\end{figure}

\section{Case study 2: Category learning}

Here, we explore a more complex and realistic space of models and experiments.
In particular, we analyze a classic paper in the psychology of categorization by Medin and Schaffer \cite{medin78:pr} that aimed to distinguish two competing models of category learning -- the \emph{exemplar model} and the \emph{prototype model}.
Using intuition, Medin and Schaffer (MS) designed an experiment where the models made diverging predictions and found that the empirical data from this experiment supported the exemplar model.
Subsequently, many other authors followed their lead, replicating and using this experiment to test competing models.

Here, we ask: how good was the MS experiment?
Could they have run an experiment that was more information-theoretically efficient?
Using our OED framework, we find that there are many superior experiments that Medin and Schaffer could have designed but did not.\footnote{Our work here is an exercise in counterfactual history; the Medin and Schaffer models are not state of the art. We chose the Medin and Schaffer research (rather than newer work) as an object of study because it commits to a clear set of competing models and a clear set of possible experiments.}



\subsection{Models}

Both the exemplar and prototypes model are classifiers that map inputs (objects represented as a vector of Boolean features) to a probability distribution on the categorization response (a label: A or B).
The exemplar model assumes people store information about every instance of the category they have observed; categorizing an object is thus a function of the object's similarity to all of the examples of category A versus the similarity to all of B's examples.
By contrast, the prototype model assumes assumes that people store a measure of central tendency for each category---a prototype.
Categorization of an object is thus a function of its similarity to A prototype  A versus its similarity to the B prototype.
For details, see the supplement.

\subsection{Experiments}

Participants first learn about the category structures in a training phase where they perform supervised learning of a subset of the objects and are then tested on this learning in a test phase.
During training, participants see a subset of the objects presented one at a time and must label each object.
Initially, they can only guess at the labels, but they receive feedback so that they can eventually learn the category assignments.
After reaching a learning criterion, they complete the test phase, where they label all the objects (training set and the held out test set) without feedback.

Medin and Schaffer (MS) used visual stimuli that varied on 4 binary dimensions (color: \emph{red} vs. \emph{green}, shape: \emph{triangle} vs. \emph{circle}, size: \emph{small} vs. \emph{large}, and count: \emph{1} vs. \emph{2}).
For technical reasons, they considered only experiments (1) having linearly separable decision boundaries and (2) containing 5 A's and 4 B's in the training set.
There are, up to permutation, 933 experiments that satisfy these constraints.
%This space is roughly two orders of magnitude larger than the space of subjective randomness experiments we considered before, although it is small enough to fully enumerate in a reasonable amount of time.

\subsection{Predictions of optimal experimental design}

We computed the expected information gain for all 933 experiments and found that the best experiment (for a single participant) had an expected information gain of 0.08 nats, whereas the MS experiment had an expected information gain of only 0.03 nats; thus, the optimal experiment is expected to be 2.5 times more informative than the MS experiment.
Indeed, the MS experiment ranks 665th out of 993 experiments total (Figure~\ref{fig:dist}a) \lou{rerun this with unconditioned prior}.

Why is the MS experiment ineffcient?
One reason is that Medin and Schaffer prioritized experiments that predict a qualitative swap in ranking for two stimuli. \lou{expound here}
The experiment they designed indeed predicts a swap, but this has a small magnitude and comes at the expense of little information gain from the remaining stimuli.
The optimal experiment is better able to quantitatively disambiguate the models by maximizing the information from all the stimuli simultaneously.
% \lou{note that the OED framework is quite flexible. in our model space, we can also encode hard constraints like ``the models must predict different rank orderings''}

\begin{figure}[t]
\centering
\begin{tabular}{l l}
(a) & (b)\\
\includegraphics[width=2.5in]{img/dist.eps} & \includegraphics[width=2.5in]{img/category-ns.pdf}\\
\end{tabular}
\caption{Comparing MS experiment with optimal experiment. MS experiment has lower expected information gain and requires twice as many participants to achieve maximum actual information gain.}
\label{fig:dist}
\end{figure}

\subsection{Empirical validation}

To validate our expected information gain calculations, we ran the MS and optimal experiments with 60 participants each.
Figure~\ref{fig:dist}b shows that both experiments achieve maximal actual information gain but the optimal experiment takes only 10 participants to asymptote to this maximum, whereas the MS experiment takes around 30.
Thus, the optimal experiment provides the same amount of information for 1/3 the experimental cost.

% and illustrates how automated experiment design can outperform human intuition. In particular, this case study demonstrates the efficacy of OED in psychology for discrete and non-ordinal experiment spaces, large combinatoric experiment spaces, and parametric model classes.

\section{Related work}

In our reading of the literature, we found that the basic intuition behind OED---to find experiments that maximize some expected measure of informativeness---has been independently discovered in a number of fields, including physics (berg03), chemistry (huan10), biology (vanlier12, liepe13), psychology (myung09), statistics (lindley72), and machine learning (golovin10).

These papers, however, often implement OED in a one-off fashion, specializing for  particular models (e.g., in biology: parameter estimation for ODEs with Gaussian noise) and commiting to a single inference technique (e.g., Metropolis-Hastings).
By contrast, we show that OED can be expressed as a generic, concise, and flexible function in a probabilistic programming language, which allows practitioners to rapidly explore different spaces of models, experiments, and inference algorithms.
Additionally, our work is the first to (1) demonstrate that expected information gain is a reliable predictor of actual information gain and to (2) characterize the cost benefits of OED.

\section{Conclusion}

Practitioners aim to design experiments that yield informative results.
Our approach partially automates experiment design, searching for experiments that maximally update beliefs about the model distribution.
With our approach, the scientist writes her hypotheses as probabilistic programs, sketches a space of possible experiments, and turns the crank of Bayesian inference.
We stress that our work \emph{complements} practitioners; it does not replace them.
Our tool eliminates the need to manually comb large spaces in search of good experiments; we hope that this will free scientists and engineers to work on the more interesting problems---devising empirical paradigms and building models.

We close by outlining some interesting directions for future work.
First, we chose KL divergence between posterior and prior as our informativeness measure because it is a well-known divergence function, but other choices (e.g., TV distance) might also be suitable.
Second, there might exist inference techniques that take advantage of the particular structure of the OED problem (e.g., if $p(y)$ is negligible, it may be acceptable to have a less precise estimate of information gain).
Third, we have restricted attention to ``one-shot'' experiments, but it would be interesting to extend our work to sequential settings (e.g., adaptive staircases in psychophysics experiments).
Fourth, we have ignored the cost of experiments, but it would be worth explicitly taking this into account.
Our informativeness approach could be usefully integrated with multi-objective optimization methods for real-world applications (e.g., MRI studies of rare patient populations, expensive aerospace experiments).
\lou{Finally, we did our case studies in cognitive psychology; we believe it's broadly useful, but people should test this.}

\bibliographystyle{ieeetr}
\bibliography{oed_nips_2016}

\end{document}
